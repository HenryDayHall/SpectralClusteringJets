\section{Method}
In this section the methodology is covered in four parts.
Firstly, the practical procedure chosen in this work for applying \spectral{} clustering  is given.
Secondly, choices and interpretations for the variable parameters in this algorithm are given.
Thirdly,  the datasets against which this will be measured are specified.
Fourthly, the procedure for checking IR safety is described.

    \begin{figure}[!t]
        \center
        \includegraphics[width=0.7\textwidth]{graphics/embedding_space_simple2.pdf}
        \caption{A single event and its embedding space, as created by \spectral{} clustering.
            At the top the grey plot shows the particles in the event as points on the unrolled detector barrel.
            The colour of each point indicates the shower it came from.
            The lower two plots show the first 4 dimensions of the embedding space,
            and the location of the points within the embedding space.}\label{fig:embedding_space_simple}
    \end{figure}    


For clarity, note that the variable pseudorapidity is never used in this work,
all references to rapidity should be understood as;
\begin{equation}\label{eqn:rapidity}
    y = \frac{1}{2} \text{ln}\frac{E + p_z}{E - p_z}
\end{equation}


\subsection{Spectral clustering algorithm}\label{sec:spectralmethodalgo}
    For every simulated event the following process is used to identify the jets.
    To begin with, relevant cuts are applied to the particles to simulate the detectors reconstruction capability.
    (These are described in detail in section~\ref{sec:particle_data}.)
    Then all particles are declared pseudojets  and given an index, \(j = 1 \dots n\), with no particular order.
    The algorithm is recursive and agglomerative, hence, the first time 
     step is labelled \(t=1\).

    \begin{enumerate}
        \item \label{step:start} The pseudojets are used to form the nodes of a graph,
        the edges of which will be weighted by some measure of proximity between the particles called affinity.
        To obtain an affinity, first a distance is obtained.
        Between pseudojets \(i\) and \(j\) this would be \(d(t)_{i,j} = \sqrt{(y(t)_i - y(t)_j)^2 + (\phi(t)_i - \phi(t)_j)^2}\)
        where \(y(t)_j\) is the rapidity of pseudojet \(j\) at time step \(t\) and \(\phi(t)_j\) is the barrel angle, likewise for \(i\).
        No \(p_T\) dependence is used.

    \item \label{step:affinity} The affinity must increase as pseudojets become more similar, whereas the distance will shrink.
        This is done by taking an exponent so that \(a(t)_{i,j} = \text{exp}(-d(t)_{i,j}^\alpha/\sigma_v)\), as done in~\cite{hadjighasem2016votex}.
            Distances much larger than \(\sigma_v\) are only allowed very small affinities,
            thus less influence over the clustering.

    \item\label{step:KNN} The affinity between pseudojets that are far apart contains less useful information, hence,
        such pseudojets are unlikely to be good combinations.
        Removing these affinities reduces noise.
    A fixed number, \(k_\text{NN}\), of neighbours of each pseudojet is 
    preserved while all other affinities are set to zero.
    Thus, in a group with more than \(k_\text{NN}\) pseudojets,
    each pseudojet has at least \(k_\text{NN}\) non-zero affinities with other pseudojets.

\item\label{step:laplacean} These affinities allow the construction of a Laplacian.
        The Laplacian used is the symmetric Laplacian, which is proportional to \(-a(t)_{i, j}\)
        in the \(i\)$^{\rm th}$ row and \(j\)$^{\rm th}$ column and exactly \(1\) on the diagonal.
        For ease of notation, let \(z(t)_j\) be a measure of the size a pseudojet \(j\) contributes to a cluster,
        with \(z(1)_j = \sum_k a_{i,k}\).
        The Laplacian can now be written as
    \begin{equation}\nonumber
        L(t) = 
        \begin{pmatrix}
            z(t)_1      & 0   & 0  & \hdots \\
            0     & z(t)_2 &    0     & \\
            0     &    0     & z(t)_3 & \\
            \vdots   &          &     & \ddots 
        \end{pmatrix}^{-\frac{1}{2}}
        \begin{pmatrix}
            z(t)_1 & -a(t)_{1,2} & -a(t)_{1,3} & \hdots \\
            -a(t)_{1,2} & z(t)_2 & -a(t)_{2,3} & \\
            -a(t)_{1,3} & -a(t)_{2,3} & z(t)_3 & \\
            \vdots   &          &     & \ddots 
        \end{pmatrix}
       \end{equation}
       \begin{equation}\label{eqn:Laplacian}
      \hspace*{-5.1truecm}
        \begin{pmatrix}
            z(t)_1      & 0   & 0  & \hdots \\
            0     & z(t)_2 &    0     & \\
            0     &    0     & z(t)_3 & \\
            \vdots   &          &     & \ddots 
        \end{pmatrix}^{-\frac{1}{2}}.
    \end{equation}
        When two pseudojets are combined, instead of calculating \(z_j\) as the sum of the affinities of the combined pseudojet,
        the new \(z_j\) is the sum of the two previous \(z_j\)'s.
        For example, if pseudojets \(1\) and \(2\) from \(t=1\) are to be combined to make pseudojet \(1\) in \(t=2\),
        then \(z(2)_{1} = z(1)_1 + z(1)_2\) rather than the sum of affinities between the new pseudojet \(1\) and other pseudojets in step \(t=2\).
        This condition is required for IR safety.  % TODO add some discussion/proof

        As such, after the first time step, \(L\) will no longer be a proper graph Laplacian.
        Its rows and columns do not sum to zero.
        However, this new \(L\) is a small perturbation from a proper Laplacian,
        and so maintains similar behaviour.

    \item \label{step:eigenvectors} From the Laplacian eigenvectors are calculated to create the embedding space and labelled with index \(q\):
            \begin{equation}
                L(t)h_q(t) = \lambda_q(t) h_q(t).
            \end{equation}
            All non-trivial eigenvectors, corresponding
            to an eigenvalue less that the eigenvalue limit, \(\lambda_q(t) < \lambda_\text{limit}\),
            are retained.
            Then the index runs over \(q = 1 \dots c\),
            see section~\ref{sec:eig_norm}.

        \item \label{step:compression} A eigenvector is divided by the corresponding eigenvalue raised to \(\beta\).
            This acts to compress the dimensions that hold less information, again, see section~\ref{sec:eig_norm}.
            The embedding space can now be formed.
            The eigenvectors have as many elements as there are pseudojets and the coordinates of
            the \(j^\text{th}\) pseudojet at time step \(t\)
            become \(m(t)_j = \left(\lambda_1(t)^{-\beta} h_1(t)_j, \dots \lambda_c(t)^{-\beta} h_c(t)_j\right)\).
            %The first embedding space of a clustering is shown in Fig.~\ref{fig:embedding_space_simple}.

        \item  A measure of distance between all pseudojets in the embedding space is calculated.
            In the embedding space angular distances are most appropriate (see section~\ref{sec:embedding_distance}):
            \begin{equation}
                d'(t)_{i, j} = \text{arccos}\left|\frac{m(t)_i.m(t)_j}{{||m(t)_i||}_2 {||m(t)_j||}_2}\right|.
            \end{equation}

        \item\label{step:stoppingcondition}

            Provided the mean of this distance is less than \stoppingdeltar{}, that is,
            \begin{equation}
                \frac{1}{c}\sum_{i\ne j} d'(t)_{i, j} < \stoppingdeltar{},
            \end{equation}
            then the two pseudojets that have the smallest embedding distance are combined.
            (Reasons for this stopping condition are given in section~\ref{sec:stopping_condintion}.)
        The two pseudojets that have been combined are removed and replaced with one pseudojet.
        In physical space the new pseudojet is created by summing the respective four-momenta of the removed pseudojets.
        Once two pseudojets have been combined in physical space, the embedding space is recalculated from step~\ref{step:start}, 
        to begin time step \(t+1\).
        There will be one fewer row and column in the Laplacian of step \(t+1\).
     \end{enumerate}
    %  
    When the mean of the distances in the embedding space rises above \stoppingdeltar{},
    then all remaining pseudojets are promoted to jets.
    Jets with less than 2 tracks are removed and their contents considered noise.
    Further cuts may then be applied as described in section~\ref{sec:particle_data}.

    These steps will form a variable number of jets from a variable number of particles.
    An example of the constructed first embedding space is shown in Fig.~\ref{fig:embedding_space_simple}.
    This illustrates how the embedding space highlights the clusters.

\subsection{Tunable parameters}\label{sec:spectralmethodparam}
Unlike most Machine Learning (ML) techniques, \spectral{} clustering does not have large arrays of learnt parameters.
The parameters for the clustering are a small, interpretable  set.
Appropriate values were chosen by performing scans and observing the influence of changes to the parameters on jets formed.

In section~\ref{sec:spectralmethodalgo}, 6 parameters are named:
\(\sigma_v\), \(\alpha\), \(k_\text{NN}\), \(\lambda_\text{limit}\), \(\beta\) and \stoppingdeltar{}.
These parameters have a range of values for which sensible results are obtained.
The interpretation of these parameters is as follows.
\begin{itemize}
    \item \(\sigma_v\): introduced in step~\ref{step:affinity}, this is a scale parameter in physical space.
                      The value indicates an approximate average distance for particles in the same shower,
                      or alternatively, the size of the neighbourhood of each particle.
                      It is closely tied to the stopping parameter for the \genkt{} algorithm, \ktstoppingdeltar{},
                      they both relate to the width of the jets formed.
                      It should take values on the same order of magnitude as \ktstoppingdeltar{}, i.e., of \(\mathcal{O} (0.1)\).
    \item  \(\alpha\): also introduced in step~\ref{step:affinity},
           this changes the shape of the distribution used to describe the neighbourhood of a particle.
           Higher values make the probability of joining particles outside \(\sigma_v\) fall away faster.
           Traditionally, the value used here is \(2\), like in a Gaussian distribution.
       \item \(k_\text{NN}\): introduced in step~\ref{step:KNN}, this dictates the minimum number of non-zero affinities around each point.
           Lower values create a sparser affinity matrix, reducing noise at the potential cost of lost signal.
           Values above \(7\) are seen to have little impact.
       \item  \(\lambda_\text{limit}\): introduced in step~\ref{step:eigenvectors}, is a means of limiting the number of eigenvectors used
           to create dimensions in the embedding space.
           Only eigenvectors corresponding to eigenvalues less than \(\lambda_\text{limit}\) are used.
           Thus, the number of dimensions in the embedding space can be increased with a larger \(\lambda_\text{limit}\),
           however, as the eigenvalues will be influenced by the number of clear clusters available, 
           there will not be the same number of dimensions in each event.
           (This is discussed in section~\ref{sec:eig_norm}.)
           For a symmetric Laplacian the eigenvalues are \(0 < \lambda < 2\),
           so values of \(\mathcal{O} (0.1)\) are sensible choices.
       \item  \(\beta\): introduced in step~\ref{step:compression}, it 
          accounts for variable quality of information in the eigenvectors, as given by their eigenvalues,
        in such a way that the dimensions of the embedding spaces with lower quality information are compressed.
        The larger the value of \(\beta\) the more dimensions with lower quality information are compressed.
        (This is discussed in section~\ref{sec:eig_norm}.)
%        This is should be \(\mathcal{O}(1)\).
    \item \stoppingdeltar{}: is introduced in step~\ref{step:stoppingcondition}, it
         determines the expected spacing between jets in the embedding space.
         As the number of dimensions in the embedding space grows with increasing 
         number of clear clusters, it will not result in the same or
         similar number of clusters each time.

\end{itemize}


%A number of other parameters that could influence clustering were experimented with,
%including changed of Laplacian and parameters using \(p_T\).
%These modifications did not seem to improve performance, so they are not included.

To investigate the behaviour of the clustering when the parameters change, scans where performed.
On a small sample of 2000 events  the clustering is performed with many different parameter choices.
%
With the aid of MC truth information a metric of success can be created.
For each object we wish to find (e.g., a \bthing{quark}) 
the MC truth can reveal which of the particles that are visible to the detector have
been created by that object.
In many cases, a particle seen in the detector will have been created by two objects,
such as a particle coming from an interaction between a \(b\bar{b}\) pair,
in these cases both objects are considered together.
The complete set of visible particles that came from these objects could be referred to as their descendants.
The aim in jet clustering is to capture only all of the descendants in the same number of jets as there were objects that created them.
So the descendants of a \(b\bar{b}\) pair should be captured in exactly 2 jets.

    \begin{figure}[!t]
        \begin{minipage}[c]{0.6\textwidth}
            \includegraphics[width=1\textwidth]{graphics/trangle_scan_genkt}
        \end{minipage}\hfill
        \begin{minipage}[c]{0.35\textwidth}
            \caption{The \genkt{} algorithm has 2 parameters that can be varied.
                The stopping condition, \ktstoppingdeltar{}, and a multiple for the exponent of the \(p_T\) factor.
                When the exponent of the \(p_T\) factor is \(-1\) the algorithm becomes the \antikt{} algorithm.
                Here, the ``Loss'', as described in Eq.~(\ref{eqn:loss}), is shown as a colour gauge for a number of parameter combinations.
                {\textcolor{red}{Please change $R_{\rm kt}$ to \(\stoppingdeltar{}_{k_T}\) in the y label and add the label Loss near the colour gauge} \textcolor{blue}{H. done}}
             }\label{fig:scan_genkt}
        \end{minipage}
    \end{figure}    

There are two ways a jet finding algorithm can make mistakes in this task:
the first is to omit some of the descendants of the objects being reconstructed, causing the jet to have less mass than it should;
the second is to include particles that are not in the descendants of the objects being reconstructed, such as initial state radiation or particles from other objects,
causing the jet to have more mass than it should.
The effects of these mistakes will cancel in the jet mass,
but they are both still individually undesirable,
so separate metrics are made for each of them.
The first is ``signal mass lost", the difference between the mass of the jets and the mass they would have had if all they contained all descendants of the object being reconstructed.
The second is ``background contamination", the difference between the mass of jets and the mass they would have if they did not contain anything but descendants of the objects being reconstructed.
When working with an \antikt{} algorithm increasing \ktstoppingdeltar{} will result in lower signal mass loss, in exchange for a higher background contamination.
The standard choice for this process with \(\ktstoppingdeltar{}_{k_T}=0.8\), slightly prefers suppressing signal mass lost over background contamination,
this leads to the clearest mass peaks.
When the metrics are combined into a single ``Loss'' value, this is accounted for by weighting;
\begin{equation}\label{eqn:loss}
\text{Loss} = \sqrt{0.73\,(\text{Background contamination})^2 + (\text{Signal mass lost})^2}.
\end{equation}
Where \(0.73\) is the weighting used to to account for the aforementioned preference for suppressing signal mass lost over background contamination.
{\textcolor{red}{Please explain the origin of that 0.73}} {\textcolor{blue}{H. improved?}}

An example of this scan for the \genkt{} algorithm is given in Fig.~\ref{fig:scan_genkt}. 
It can be seen that, while good results are possible with many values of the \(p_T\) exponent,
                \ktstoppingdeltar{} must fall in a narrow range. We thus deem this choice of  stopping condition, \(\stoppingdeltar{}_{k_T}=0.8\), to be rather fine-tuned.

For \spectral{} clustering there are more than 2 variables to deal with, 
so a set of two dimensional slices are extracted. 
These slices have been chosen to include the best performing combination.
%
    As can be seen in Fig.~\ref{fig:scan_spectral}, the parameters choices  are not fine-tuned. That is, 
    unlike the \antikt{} algorithm, there is flexibility in all parameter choices. For example, it can be seen that some parameters, such as \(\alpha\), \(k_\text{NN}\), \(\beta\)
                and \(\lambda_\text{limit}\) are relatively insensitive.
                They give good results in a wide range of values.
                Even when \stoppingdeltar{} and, especially, \(\sigma_v\) yield some large signal losses, say, for $R=1.22$ or 1.3 and $\sigma_v=0.05$, this happens is very narrow ranges.  For definiteness, the
    parameters used in the remainder of this work are \(\alpha=2.\), \(k_\text{NN}=5\), \(\stoppingdeltar{} = 1.26\), \(\beta = 1.4\), \(\sigma_v = 0.15\) and \(\lambda_\text{limit} = 0.4\).
\clearpage
    \begin{figure}[!t]
            \includegraphics[width=1\textwidth]{graphics/trangle_scan_complete}
            \caption{There are 6 free parameters in \spectral{} clustering.
                Here, the ``Loss'', as described in Eq.~(\ref{eqn:loss}), is shown for reasonable  parameter ranges chosen
                either by convention (e.g., \(\alpha\) is typically \(1\) or \(2\))
                or according to physical scales (e.g., $\sigma_v$ is of order \(0.1\)).
                {\textcolor{red}{Please remove the equation next to the colour gauge and just leave Loss in horizontal}
                \textcolor{blue}{H. will do}}
             }\label{fig:scan_spectral}
    \end{figure}    


    \subsection{Particle data}\label{sec:particle_data}

To evaluate the behaviour of the spectral clustering method four datasets are used\footnote{The first two uses a 2-Higgs Doublet Model (2HDM) setup as described in Ref.~\cite{Chakraborty:2020vwj} while the last two are purely Standard Model (SM) processes. Notice that all unstable objects are rather narrow, including the Beyond the SM (BSM) Higgs states \cite{Moretti:1994ds,Djouadi:1995gv}, so that we have neglected interference effects with their irreducible backgrounds.}, all produced for the Large Hadron Collider (LHC).

    \begin{enumerate}
        \item 
    \underbar{Light Higgs} A SM-like Higgs boson with a mass \(125\) GeV decays into two light Higgs states with mass  \(40\) GeV,
    which in turn decay to \beau{}\bbar{} quark pairs.
    That is, the process is \(p p \rightarrow H_{125\,\text{GeV}} \rightarrow h_{40\,\text{GeV}} h_{40\,\text{GeV}} \rightarrow \beau \bbar \beau \bbar\), simulated at Leading Order (LO).

\item \underbar{Heavy Higgs}  A heavy Higgs boson with a mass \(500\) GeV decays into two SM-like Higgs states with mass  \(125\) GeV,
    which in turn decay to \beau{}\bbar{} quark pairs.
    That is, the process is \(p p \rightarrow H_{500\,\text{GeV}} \rightarrow h_{125\,\text{GeV}} h_{125\,\text{GeV}} \rightarrow \beau \bbar \beau \bbar\), simulated at LO.

\item \underbar{Top}  A $t\bar t$ pair decays semileptonically, i.e., where one \(W^\pm\) decays to a pair of quark jets $jj$ and the other into a lepton-neutrino pair $\ell\nu_\ell$ ($\ell=e,\mu$).
        That is, the process is \( p p \rightarrow t \bar{t} \rightarrow b\bar b W^+  W^-\to b\bar b jj \ell\nu_\ell\), simulated at LO. (Note that, here, $m_t=172.6$ GeV and $m_{W}=80.4$ GeV.)
        
    \item \underbar{3-jets}  For the purpose of checking {IR safety}, we have used three-jet events,         this being a rather simple configuration where IR singularities could be observed. 
        That is, the process is $pp\to jjj$, simulated at both LO and Next-to-LO (NLO). 



    \end{enumerate}

    Using MadGraph~\cite{alwall_madgraph2011} to generate the partonic process and Pythia~\cite{sjostrand_pythia2015} to shower, ${\cal O}(10^5)$ of each of these processes are generated.
    A full detector simulation is not used, instead, cuts on the particles are imposed to approximate detector resolution, as detailed below. 
    {\textcolor{red}{Explain how the detector was simulated.}\textcolor{blue}{H. does this work?}}
    
    The Center-of-Mass (CM) energy used is \(\sqrt{s}=13 \) TeV.

    Each event also contains (hard) Initial State Radiation (ISR) and soft QCD dynamics from beam remnants, i.e., the Soft Underlying Event (SUE).
    There is no pileup or multiparton interactions in the datasets.
%    ISR is other emissions from the quarks that create the signal process, such as radiated gluons.
%    Beam remnants are emissions coming from the part of the proton that is not directly involved in creating the signal process.
    {\textcolor{red}{What about MPIs and pile-up?}\textcolor{blue}{H. we have neither}}

    Each of these datasets requires different cuts, both at the particle level, to simulate detector coverage, and at the jet level, to select the best reconstructed events.
    The cuts on each dataset are as follows.
    \begin{enumerate}
        \item The reconstructed particles are required to have
            rapidity \(|\eta|< 2.5\) and (transverse momentum \(p_T > 0.5\) GeV.
            These cuts are likely to remove the majority of the radiation from beam remnants
            and reduce the radiation from ISR.
%            After cuts, \(72\%\) of events have at least \(5\) \bthing{shower} particles and \(5\) pure ISR shower particles available.
            The $b$-jets are required to have \(p_T > 15\) GeV, which is possibly lower than is realistic \cite{Chakraborty:2020vwj},
            but it leaves a larger number of events to compare the behaviour of jet clustering algorithms.

        \item  The reconstructed particles are required to have
             \(|\eta|< 2.5\) and \(p_T > 0.5\) GeV.
            The $b$-jets are required to have \(p_T > 30\) GeV, which is realistic for efficient $b$-tagging performance and further reduces ISR and the SUE.
            
        \item The reconstructed particles are required to have
             \(|\eta|< 2.5\) and \(p_T > 0.5\) GeV.
            The event is required to have  \(p_{T}^{\text{miss}} > 50\) GeV,
            where \(p_{T, \text{miss}}\) is the missing transverse momentum due to 
            the neutrino.
            The lepton in the event must have  \(|\eta|< 2.4\).
            If the lepton  is a muon then its \(p_T\) must be \(>  55\) GeV.
            If the lepton  is an electron and it is isolated (as defined in~\cite{Sirunyan_2018}) then its \(p_T\) must be \(> 55\) GeV, if it is not isolated then \(p_T > 120\) GeV.
            The reconstructed jets must have \(p_T > 30\) and \(|\eta|< 2.4\).
            Finally, the lepton must be seperated from the closest jet by at least
            \(\sqrt{\Delta\eta^2 + \Delta \phi^2} > 0.4\) or
            \(p_{T}^{\text{relative}} > 40\) GeV.
            These cuts are copied from~\cite{Sirunyan_2020}.
        \item The only restriction on the particles is that the rapidity must be \(< 2.5\).
            There are no cuts on the jets. While unrealistic, since 
            issues of IR safety are emphasised at low \(p_T\),  to highlight this we abandon all \(p_T\) cuts.

    \end{enumerate}


    The Higgs boson cascade datasets have the desirable property of creating \bthing{jets} with different kinematics: while in case 1 we may expect some slim  jets (as on average they are rather stationary, because of the small mass difference between $H_{125\,{\rm GeV}}$ and $H_{40\,{\rm GeV}}$)
in case 2 we may see mainly fat jets (owing to the boost provided by the large mass difference between $H_{500\,{\rm GeV}}$ and $H_{125\,{\rm GeV}}$).
%In both cases we require 4 $b$-jet events. In case 3 we require 2 $b$-jets, 2 light-jets, one lepton and missing transverse energy.  In case 4, we require exactly 3 jets, whichever their composition.
Mass reconstruction requirements for the \underbar{Light Higgs} and \underbar{Heavy Higgs} follow the same logic.
In order to reconstruct a Higgs decaying directly to a pair of \bthing{quarks}, we require a separate jet tagged by each \bthing{quark}, that is, two jets are required, each tagged by a \bthing{quark} from that Higgs.
To reconstruct a Higgs that decays to a pair of child Higgs, we require both child Higgs have been reconstructed, that is, all four \bthing{jets} are found.
In the case of the \underbar{Top} events, three masses can be reconstructed from jets, the hadronic \(W\), the ahdronic top and the leptonic top.
The hadronic \(W\) is reconstructed if both of the quarks it decayed to have tagged jets, they are permitted to tag the same jet, so the hadronic \(W\) can be reconstructed from one or two jets.
The hadronic top is reconstructed if the hadronic top is reconstructed and the \bthing{quark} from the hadronic top has tagged a jet, so the correct \bthing{jet} is required in addition to the requirements on the \(W\).
The leptonic top is reconstructed if the \bthing{quark} from the top decay tags a jet, and the missing momentum calculation which reconstructs the leptonic \(W\) yields a real mass.
If the missing mass calculation for the mass of the leptonic \(W\) yields two real masses, the one closes to the \(W\) mass is selected.
{\textcolor{red}{Is this correct?}\textcolor{blue}{H. it's a little different. I have also moved it after the particle and jet cuts, as it occurs afterwards.}}

We now proceed to compare spectral to anti-$k_T$ clustering and we start from testing IR safety of the former, while this is a well-known feature of the latter. We will then move on to study Higgs boson and top quark events.

    %\begin{figure}[htp]
    %    \begin{minipage}[c]{0.5\textwidth}
    %        \includegraphics[width=1\textwidth]{graphics/binned_events.png}
    %    \end{minipage}\hfill
    %    \begin{minipage}[c]{0.45\textwidth}
    %        \caption{The end state particles in the simulated events are filtered
    %            with the standard cuts, \(p_T > 0.5\), \(|\eta| < 2.5\).
    %            The events are binned according to how many particles remain after the cuts.
    %            The percentage of \bthing{descendants} in the remaining event after the cuts
    %            is averaged for each bin and plotted on the same axis.
    %            After the cuts have been applied most events are left with around \(50\) particles.
    %                 The percentage of particles that are descendant from a \bthing{quark} varies,
    %                 it is at its highest in events with \(50\) particles,
    %             and most variable in events will small multiplicity.
    %            Very large and very small events tend to be mostly background,
    %            mid sized events are mostly signal.
    %         }\label{fig:bdecendantpercent}
    %    \end{minipage}
    %\end{figure}    
    %
    %
    %\begin{figure}[htp]
    %    \begin{minipage}[c]{0.5\textwidth}
    %        \includegraphics[width=1\textwidth]{graphics/event_composition.png}
    %    \end{minipage}\hfill
    %    \begin{minipage}[c]{0.45\textwidth}
    %        \includegraphics[width=1\textwidth]{graphics/event_composition_nocuts.png}
    %        \caption{Left = with cuts, right = without cuts.
    %         }
    %    \end{minipage}
    %\end{figure}    
    %
    %
    %\begin{figure}[htp]
    %    \begin{minipage}[c]{0.5\textwidth}
    %        \includegraphics[width=1\textwidth]{graphics/event6.pdf}
    %    \end{minipage}\hfill
    %    \begin{minipage}[c]{0.45\textwidth}
    %        \caption{Drawing of initial state radiation of the 6th even in the dataset.
    %                 The Monte Carlo simulation considers multiple interactions in each vertex,
    %                 and so vertices should eb seen as the combination of multiple steps.
    %                 The information displayed here is what is recorded in the \lstinline{.hepmc} file
    %                 produced by \lstinline{Delphes}.
    %                 A gluon coming from the \(u\) in the left proton producing radiation (the \(c\) and \(g\)) leads to detectable showers.
    %                 The up quark from the right hand proton would have created a shower, but the shower is undetected, either due to high rapidity or low \(p_T\).
    %             Showers are often contributed to from many parts of the initial state radiation, so attributing them has some ambiguity.}
    %        \label{fig:isr}
    %%        \includegraphics[width=1\textwidth]{graphics/initalstaterdiation_sources.png}
    %%        \caption{In the plot the energy of the initial state particle is used to guess its contribution to the mass of the resulting shower.
    %%            This is done after detector cuts (particle \(p_T > 0.5\) and \(|\text{rapidity}| < 2.5\))
    %%        Taking this rule, on average each event has about \(3\)GeV worth of radiation from initial state gluons.
    %%        Other initial state particles contribute smaller amounts of radiation.}
    %%                 
    %    \end{minipage}
    %\end{figure}    
    %A particle is considered a \bthing{descendant} if it is found in the chain of decays from a \bthing{quark},
    %as opposed to decaying from the ISR.
    %Exactly how the percentage of \bthing{descendants} changes with event size is visualised in Fig.~\ref{fig:bdecendantpercent}.

\subsection{Determining IR safety}\label{sec:IRmethod}
    It would be possible to demonstrate IR safety analytically, however,
    as the environment required for clustering on MC data is already set up,
    it is more efficient for this study to prove IR safety with such data.
    This can be done by showing that an IR sensitive variable, for example, the jet mass spectrum,
    is stable between a LO dataset with no IR singularities and a NLO
    one which will instead contain IR singularities.

    Showing the jet mass spectrum at LO and NLO for a particular configuration,
    that is, a particular selection of clustering parameters,
    would allow a comparison that would highlight any differences caused by IR sensitivity.
    This will be done for illustrative purposes,
    however, even an IR unsafe algorithm, such as the iterative cone one~\cite{cacciari_antikt2018},
     has some configurations for which these singularities are avoided.

    To provide a more global view, a scan of parameter configurations must be compared.
    Thus, for an unsafe algorithm (such as the iterative cone) the unsafe configuration
    will be found.
    It would be cumbersome to compare all these jet mass spectrum by eye, however.
    Instead, we introduce a summary statistic representing the divergence between two distributions,
    the Jensen-Shannon score~\cite{jensen_shannon}.

    The Jensen-Shannon score is a value computed between two distributions that increases in magnitude the more these distributions differ.
    It is a symmetrised variant of the Kullback-Leibler divergence. {\textcolor{red}{[Ref needed]}\textcolor{blue}{H., the definition of JS and KL are both given in \cite{jensen_shannon}, along with an explanation of that they are. I think JS is originally from \cite{jensen_shannon}, though something similar exists in \url{https://royalsocietypublishing.org/doi/pdf/10.1098/rspa.1946.0056}. Should I be citing \cite{jensen_shannon} here?}}
    The Kullback-Leibler divergence between probability densities \(p\) and \(q\) can be written as
    \begin{equation}
    D_\text{KL} (p | q) = \int^{\infty}_{-\infty} p(x) \log\left(\frac{p(x)}{q(x)}\right) dx,
\end{equation}
    from which the Jensen-Shannon divergence can be written as
    \begin{equation}
    D_\text{JS}(p, q) = \frac{1}{2}D\left(p | \frac{1}{2}(p + q)\right) + \frac{1}{2}D\left(q | \frac{1}{2}(p + q)\right).
\end{equation}
    Here, \(D_\text{JS}\) treats \(p\) and \(q\) symmetrically and will grow as they become more different.
    The spectrum of Jensen-Shannon scores will be plotted for a known IR safe clustering algorithm, \antikt{},
    a known unsafe clustering algorithm, iterative cone, and the \spectral{} algorithm.
    If the Jensen-Shannon scores for \spectral{} are consistently small,
    then it is IR safe.

    %One small issue with this method is that a large \(D_\text{JS}\) would not differentiate
    %between a change in \(p\) and \(q\) due to IR sensitivity and 
    %a change due to noise in the jet mass spectrum.
    %The more events used to find the jet mass spectrum the lower the expected noise,
    %however, it is is also possible to subsample within a distribution (LO or NLO)
    %to discover how much \(D_\text{JS}\) is influenced by noise.
    %If two random sets of jet masses, from events \(a\) and events \(b\), are drawn from the LO events 
    %and a \(D_\text{JS}(a, b)\) is computed between them, a large value will indicate that 
    %noise in the spectrum is increasing the size of \(D_\text{JS}\) between the LO and NLO spectra.
    %To account for this, a subsampled \(D_{\rm JS}\) can be constructed:
    %\begin{equation}
    %D_{\rm JS, subsampled}(p, q) = \frac{cD_{\rm JS}(p, q)}{\sum_{a \in p, b \in p} D_{\rm JS}(a, b)\sum_{c \in q, b \in q} D_{\rm JS}(c, d)}.
    %\end{equation}
    %If this does not differ too much from \(D_{\rm JS}\) then the data sets are large enough so that the noise in
    %the spectra is not influencing the results.
